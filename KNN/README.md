# ğŸ©º Disease Prediction using K-Nearest Neighbors (KNN)

This project uses the K-Nearest Neighbors (KNN) algorithm to predict diseases based on the symptoms provided by a patient. It's a multi-class classification problem that demonstrates how distance-based algorithms can be applied in healthcare scenarios.

---

## ğŸ“ Project Overview

- ğŸ“Š Problem Type: Multi-class Classification  
- ğŸ¯ Objective: Predict the most likely disease using symptoms  
- ğŸ“‚ Dataset: Symptom-to-Disease Dataset (medical.csv or dataset.csv)  
- ğŸ§ª Algorithm: K-Nearest Neighbors using scikit-learn

---

## ğŸ” Dataset Description

| Feature Name   | Description                             |
|----------------|------------------------------------------|
| Symptom_1â€“6    | Categorical symptoms (e.g., vomiting, fatigue, etc.) |
| Disease        | Target variable (diagnosed disease)      |
| Classes        | 40+ different diseases                   |

Each row in the dataset represents a patient case with up to six symptoms and the corresponding diagnosed disease.

---

## ğŸ”§ Workflow Steps

1. âœ… Loaded and cleaned the dataset  
2. âœ… Retained only required columns (Symptom_1 to Symptom_6 and Disease)  
3. âœ… Filled missing values with the mode (most common symptom)  
4. âœ… Applied Label Encoding to symptoms and disease names  
5. âœ… Split data into training and testing sets (80/20 split)  
6. âœ… Trained KNeighborsClassifier from scikit-learn  
7. âœ… Tested the model on unseen test data  
8. âœ… Measured performance using Accuracy Score

---

## ğŸ“ Distance Metrics Covered

- Euclidean Distance  
- Manhattan Distance  
- Minkowski Distance

ğŸ§ª In this implementation, Euclidean distance was used by default to find the nearest neighbors.

---

## ğŸ“ˆ Model Performance

| Metric          | Result        |
|------------------|---------------|
| Train Accuracy   | 99.62%        |
| Test Accuracy    | 98.47% âœ…     |
| Neighbors (K)    | 5             |
| Distance Metric  | Euclidean     |

The model was able to generalize well and predict the correct disease based on symptoms in most test cases.

---

## ğŸ§  Key Learnings

- Understood how KNN classifies a data point by voting among k-nearest neighbors  
- Learned how to tune k-value and choose distance metrics  
- Understood pros and cons of instance-based learning  
- Demonstrated how a simple algorithm like KNN can be effective for medical predictions

---

## ğŸ“š Tools & Libraries

- Python 3  
- pandas, numpy  
- scikit-learn  
- Jupyter Notebook / Google Colab


---

## ğŸ™‹â€â™€ï¸ About Me

Hi, Iâ€™m Ruthika Nalajala â€” an aspiring Machine Learning Engineer building real-world projects as part of my learning journey through IntelPath and self-study. This project is one of many in my growing ML portfolio.

ğŸ“¬ Letâ€™s connect on [LinkedIn](https://linkedin.com/in/ruthika-nalajala-73127628b) (replace with your profile link)

---

â­ Feel free to explore, fork, or improve this project. Thanks for visiting!

