# -*- coding: utf-8 -*-
"""linearregression(insurance).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1djPs4ulV9Oq_jsCaBr2nBsOfZ9CX8ufV

#**Importing Libraries and Loading dataset**
"""

#importing libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

#loading dataset
df=pd.read_csv('/content/insurance_data.csv')
df

"""#**EDA**"""

#check for null values , duplicate values , get brief info of this dataset
#check number of rows and columns in the dataset

df.info() #info of the dataset

df.isnull().sum() #check total no.of null values in each column

df.isnull().sum().sum() #to check the total null of null values in the dataset

df.duplicated().sum()

#if i want to know how many people are smoker and how many are not
df['smoker'].value_counts()

#if we have null value in numerical column we will replace it with mean or median
#if in categorical column we will replace it with mode

col_list=list(df.columns)
print(col_list)

for x in col_list:
  if df[x].dtypes=='object':
    df[x].fillna(df[x].mode()[0],inplace=True)
  else:
    df[x].fillna(df[x].mean(),inplace=True)

df.isnull().sum() #null values are replaced

"""#**Outliers Detection**

"""

#outliers detection
plt.boxplot(df['Anual_Salary'])
plt.xlabel('Annual Salary')
plt.ylabel('Count')
plt.show()

#outlier detection for all the columns in the dataset
for x in col_list:
  if df[x].dtypes=='int64' or df[x].dtypes=='float64':
    plt.boxplot(df[x])
    plt.xlabel(x)
    plt.ylabel('Count')
    plt.show()

"""Now we have detected the outliers, we have to deal with them or remove them

"""

#finding the lower_bound and upper_bound values of bmi column

Q1= df.bmi.quantile(0.25)
Q3=df.bmi.quantile(0.75)

IQR= Q3-Q1

lower_bound= Q1-1.5*IQR
upper_bound= Q3+1.5*IQR

print(lower_bound)
print(upper_bound)

#finding all the lower_bound and upper_bound values of all the numerical columns and removing outliers

col_list=list(df.columns)
print(col_list)
for x in col_list:
  if df[x].dtypes=='object' or x=='charges':
    continue
  else:
    Q1=df[x].quantile(0.25)
    Q3=df[x].quantile(0.75)
    IQR=Q3 - Q1
    lower_bound=Q1-1.5*IQR
    upper_bound= Q3+1.5*IQR
    print(f"lower bound of {x} is {lower_bound}")
    print(f"upper bound of {x} is {upper_bound}")
    df = df[(df[x]>=lower_bound) & (df[x]<=upper_bound)]

#vizual representation of the dataset after removing outliers

import matplotlib.pyplot as plt

for x in col_list:
  if df[x].dtypes=='object' or x=='charges':
    continue
  else:
    plt.boxplot(df[x])
    plt.xlabel(x)
    plt.ylabel('Count')
    plt.show()

#There can be a possibility that catergorical columns can also be affecting my model
#But my model cannot understand the catergorical columns
#so i should convert the catergorical columns into numerical columns.

"""#**Encoding**

"""

#Encoding - the process of converting categorical (non-numerical) data into a numerical format that machine learning algorithms can understand and process
#Common Encoding Techniques
# 1.One-Hot Encoding
# 2.Label Encoding
# 3.Ordinal Encoding
# 4.Mean Encoding
# 5.Frequency Encoding

#Label Encoding - Assigns a unique numerical label to each category
#We have to import Labelencoding sklearn.preprocessing

from sklearn.preprocessing import LabelEncoder
le=LabelEncoder()

for x in col_list:
  if df[x].dtypes=='object':
    df[x]=le.fit_transform(df[x])

df

"""#**Model Building**"""

from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split

# x_train -> Training questions  independent columns
# y_train -> Training answers    dependent column
# x_test -> Testing questions of independent columns (some rows that I won't pass to the model)
# y_test -> Testing answers of dependent column (To analyse the performance of the model)

X=df.iloc[:,:12]
Y=df.iloc[:,-1]

X #independent columns

Y #dependent columns

X_train,X_test,Y_train,Y_test=train_test_split(X,Y,train_size=0.75)

X_train #Training data (questions)

Y_train #training data answers.

X_test #Testing data. after building the model I will test my model with this data.

Y_test   #When the model will predict the values for us we will compare those values with y_test

linear_model=LinearRegression()

linear_model.fit(X_train,Y_train)

#now we need to test the data to check what values my model can predict

model_predicted=linear_model.predict(X_test)
model_predicted

"""#**MSE,R2_score**"""

#MSE -> Mean Squared Error
#RMSE -> Root Mean Squared Error
#r2_score

from sklearn.metrics import mean_squared_error

mse=mean_squared_error(Y_test,model_predicted)
mse

rmse=np.sqrt(mse)
rmse

from sklearn.metrics import r2_score

r2_score=r2_score(Y_test,model_predicted)
r2_score*100

sns.regplot(x=model_predicted,y=Y_test)
plt.xlabel('Predictions')
plt.ylabel('Actual Values')
plt.title('Regression Plot')
plt.show()