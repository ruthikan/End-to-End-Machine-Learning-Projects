# -*- coding: utf-8 -*-
"""Practice_ML.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1M0-oY9xkoHAj40MWvzvzJ5Zic5_a5IcA

##**Importing Libraries and dataset**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

df=pd.read_csv('/content/census-income .csv')
df

"""##**EDA**"""

df.isnull().sum().sum()

df.duplicated().sum()

df.drop_duplicates(inplace=True)
df.duplicated().sum()

df.info()

"""##**Outliers**"""

for x in df.columns:
  if df[x].dtypes!='object':
    sns.boxplot(df[x])
    plt.xlabel(x)
    plt.show()

for x in df.columns:
  if df[x].dtypes!='object':
    q1=df[x].quantile(0.25)
    q3=df[x].quantile(0.75)
    IQR=q3-q1
    upper=q3+(1.5*IQR)
    lower=q1-(1.5*IQR)
    df=df[(df[x]>=lower) & (df[x]<=upper)]

for x in df.columns:
  if df[x].dtypes!='object':
    sns.boxplot(df[x])
    plt.xlabel(x)
    plt.show()

"""##**LabelEncoding**"""

from sklearn.preprocessing import LabelEncoder

le=LabelEncoder()
for x in df.columns:
  if df[x].dtypes=='object':
    df[x]=le.fit_transform(df[x])

df.info()

df

"""##**Model Building**"""

x=df.drop('annual_income',axis=1)
y=df['annual_income']

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score,confusion_matrix,classification_report
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=23)

"""##**1.Logistic Regression**"""

from sklearn.linear_model import LogisticRegression

model1=LogisticRegression()
model1.fit(x_train,y_train)

y_pred=model1.predict(x_test)

accuracy_score(y_test,y_pred)*100

confusion_matrix(y_test,y_pred)

print(classification_report(y_test,y_pred))

"""##**2.Decision Trees**"""

from sklearn.tree import DecisionTreeClassifier

#Brute Force to find the max_depth

max_depth=[1,2,3,4,5,6,7,8,9,10]
for i in max_depth:
  model2=DecisionTreeClassifier(max_depth=i)
  model2.fit(x_train,y_train)
  y_pred=model2.predict(x_test)
  acc=accuracy_score(y_test,y_pred)
  print(f"for the max depth {i} the accuracy score is: {acc}")

model2=DecisionTreeClassifier(max_depth=4)
model2.fit(x_train,y_train)

dt_y_pred=model2.predict(x_test)

accuracy_score(y_test,dt_y_pred)*100

from sklearn.tree import plot_tree
plt.figure(figsize=(20,10))
plot_tree(model2,filled=True,feature_names=x.columns,class_names=['<=50','>50'])
plt.show()

"""##**3.Random Forest**"""

from sklearn.ensemble import RandomForestClassifier

from sklearn.model_selection import RandomizedSearchCV

base_model=RandomForestClassifier(random_state=23)

params_grid={
    'n_estimators':[100,200,300],
    'max_depth':[1,5,10],
    'min_samples_split':[2,5,7],
    'min_samples_leaf':[1,2,4],
    'criterion':['gini','entropy']
}

random_search=RandomizedSearchCV(estimator=base_model,param_distributions=params_grid)

random_search.fit(x_train,y_train)

print(random_search.best_params_)

model3=RandomForestClassifier(n_estimators=300,min_samples_split=7,min_samples_leaf=2,max_depth=5,criterion='entropy',random_state=23)

model3.fit(x_train,y_train)

rf_y_pred=model3.predict(x_test)

accuracy_score(y_test,rf_y_pred)*100